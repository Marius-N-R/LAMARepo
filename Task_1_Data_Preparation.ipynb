{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Marius-N-R/LAMARepo/blob/Florian/Task_1_Data_Preparation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IogzxR38BjMZ"
      },
      "source": [
        "<b>Group Number:</b>\n",
        "<br><b>Name Group Member 1:</b>\n",
        "<br><b>u-Kürzel Group Member 1:</b>\n",
        "<br><b>Name Group Member 2:</b>\n",
        "<br><b>u-Kürzel Group Member 2:</b>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dg-WjExBjMb"
      },
      "source": [
        "# LAMA TASK 1 - Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzbUHisPBjMb"
      },
      "source": [
        "## General information - Task notebooks\n",
        "\n",
        "All notebooks are made in a similar scheme. There are the following block types:\n",
        "<br /><br />\n",
        "\n",
        "<b>Text block:</b>\n",
        "Introduction, description of the task, additional information. Block like this. No need to modify anything here.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-g-0ZIbBjMc"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "<b>Green blocks: Tasks or Questions.</b><br /><br />\n",
        "<b>Task:</b> Information about the task you have to do. Answer in the code block below.<br />\n",
        "<b>Question (1 pts):</b> A question to answer. Answer it in the block below.\n",
        "</div>\n",
        "\n",
        "<div class=\"alert alert-block alert-info\">\n",
        "<b>Blue blocks: Notes.</b><br /><br />\n",
        "<b>Note:</b> Some helpful information, links, etc.\n",
        "    \n",
        "<b>Hint: </b>If you work with VS Code, these blocks won't be formatted correctly! Don't miss any question block!\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hx2ne86nBjMd"
      },
      "outputs": [],
      "source": [
        "# CodeBlock \"That's your place to program!\"\n",
        "# Caution! Only write your code between the lines. (STUDENT CODE ...)\n",
        "# often, the data is prepared beforehand and important \"import\" statements are done already. Like:\n",
        "import csv\n",
        "\n",
        "# this block for example imports the LAMA checkpoint checker module that helps you to verify your answer at important places in the code\n",
        "from lama.checkpoints import lama_compare_checkpoint\n",
        "\n",
        "# Below starts your student code part. Tasks are normally stated beforehand.\n",
        "# Only put your code inbetween the Student code here parts, all other code will not be graded.\n",
        "# A student code block also gives you the number of points you can achieve with this task\n",
        "# Student code blocks may also contain some \"unfinished\" statements like variables names. E.g., in the following \"var = ...\",\n",
        "# go ahead and replace the three dots with something meaningful\n",
        "\n",
        "### STUDENT CODE HERE (0pt)\n",
        "\n",
        "var = ... #enter \"variable\"\n",
        "p = ...    #enter \"points!\"\n",
        "\n",
        "### STUDENT CODE until HERE\n",
        "\n",
        "# DO NOT WRITE HERE!\n",
        "# If you have done everything correctly, you should get some correct output statements.\n",
        "print('Often there are print statements prepared down here.')\n",
        "print(f'But sometimes it is required to fill a {var} in the student code part to get all {p}')\n",
        "\n",
        "print('It is also important to run the whole notebook and generate the output down here before you upload it!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzouReiIBjMe"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "_\"Machine Learning at its most basic is the practice of using algorithms to parse data, learn from it, and then make a determination or prediction about something in the world.\" -- Nvidia (Source: https://emerj.com/ai-glossary-terms/what-is-machine-learning/)_\n",
        "\n",
        "Well, as you might already heard, machine learning is based on data. Basically machine learning algorithms use many data samples to find a generalized solution to a given problem, once unknown or new data is used. Therefore, an important task in the beginning is proper data preparation.\n",
        "\n",
        "Hence you will learn in the first part of this session how data can be read from files. The proper data handling is then discussed. In the next part you learn how to use and utilize your data in order to get the most out of your machine learning approach.    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6V3ZeDxBjMf"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "<b>Note:</b> Some definitions.\n",
        "<ul>\n",
        "    <li> Consider a regular dataset, then one <b>sample</b> is given as a <b>row</b> and one <b>feature</b> over all samples by a <b>column</b>.\n",
        "<li> All columns are features but the one you are trying to predict or reveal tendencies is called label/target.\n",
        "<li> So to say, features are generally used as an input and labels as your output.\n",
        "\n",
        "</ul>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HRvB2fIBjMf"
      },
      "source": [
        "# 1 Load Data from CSV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9K4SMZfIBjMg"
      },
      "source": [
        "**First of all let's see what a CSV is.**\n",
        "\n",
        "A very common file format for data is CSV files. This is usually a standard for small datasets. CSV is short for **C**omma **S**eparated **V**alues. A CSV file is constructed out of rows and columns, similar to a table. Columns are separated by commas (,) and each line in the file represents a row."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-SvbTi4BjMh"
      },
      "source": [
        "As mentioned in the introduction, you will now see how to load a file and convert the input data into data types (such as integers, floats, strings etc...), which then can be handled by our Python programs. The following will provide you with the basics on how to load data.\n",
        "\n",
        "For CSV files we can use a Python standard library, which contains a `reader()` function. This function takes a file as input argument and returns a list of data rows.\n",
        "\n",
        "Let's get started with the code and create a function called `load_csv()`, which will take the filename as an argument and returns the dataset.\n",
        "\n",
        "## 1.1 Dataset\n",
        "\n",
        "During this session we use a diabetes dataset provided by the National Institute of Diabetes and Digestive and Kidney Diseases.\n",
        "\n",
        "\"The objective of the dataset is to diagnostically predict whether or not a patient has diabetes, based on certain diagnostic measurements included in the dataset. Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage.\" -- (https://www.kaggle.com/uciml/pima-indians-diabetes-database)\n",
        "\n",
        "<div class=\"alert alert-block alert-success\">\n",
        "<b>Task:</b> Complete the given <code>load_csv_one()</code> function.\n",
        "<ul>\n",
        "    <li> The reader is an object that returns the rows of the file as a list of strings</li>\n",
        "    <li> Use the list command or iterate the reader object to create your dataset</li>\n",
        "    <li> Then you can test your function, call your function and load the table and print the number of rows and columns it contains.\n",
        "</ul>\n",
        "</div>\n",
        "\n",
        "<div class=\"alert alert-block alert-info\">\n",
        "<b>Note:</b> See also https://docs.python.org/3/library/csv.html\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WtWHNfWQBjMh"
      },
      "outputs": [],
      "source": [
        "from typing import *\n",
        "\n",
        "from csv import reader\n",
        "import csv\n",
        "\n",
        "# Load a CSV file\n",
        "def load_csv_one(filename: str) -> List[List[str]]:\n",
        "\n",
        "    ### STUDENT CODE HERE (2pt)\n",
        "\n",
        "\n",
        "    ### STUDENT CODE until HERE\n",
        "\n",
        "    return dataset\n",
        "\n",
        "filename = 'data/pima-indians-diabetes.csv'\n",
        "dataset: List[List[str]]\n",
        "\n",
        "# Here you can call your function and print the number rows and columns\n",
        "### STUDENT CODE HERE (1pt)\n",
        "\n",
        "\n",
        "### STUDENT CODE until HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zRAiGyZBjMi"
      },
      "source": [
        "If we look at the structure of the data (p.ex. by using _Notepad++_ in the \"data\" folder, where the file is located), we can see, that it contains numeric data, which is seperated by commas (,) (see picture below). Let's use our written function to learn about some details of the data like the number of rows and used columns.\n",
        "![CSV.png](attachment:CSV.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVn1EOjCBjMi"
      },
      "source": [
        "Actually, there is a small problem with our function, since it will load empty lines from the data file and add them to our list of rows. We can handle this case if we are adding only rows with data in it while skipping empty rows.\n",
        "\n",
        "<div class=\"alert alert-block alert-success\">\n",
        "<b>Task:</b> Write an improved function for <code>load_csv()</code>, which skips empty rows.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zDdn_Mg-BjMj"
      },
      "outputs": [],
      "source": [
        "def load_csv(filename: str) -> List[List[str]]:\n",
        "\n",
        "    ### STUDENT CODE HERE (1pt)\n",
        "\n",
        "\n",
        "    ### STUDENT CODE until HERE\n",
        "\n",
        "# Test your new function...\n",
        "dataset: List[List[str]] = load_csv(filename)\n",
        "print(f'Loaded data file {filename} with {len(dataset)} rows and {len(dataset[0])} columns')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7-FjkDrBjMj"
      },
      "source": [
        "In general, always take a look on your data before loading it, there might be some irregularities in it, you might have to cover when loading it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLBjBDiHBjMj"
      },
      "source": [
        "## 1.2 Convert Strings to Floats\n",
        "\n",
        "The majority of all machine learning algorithms prefer to work with numbers, especially floating point numbers. But does our current code for loading a csv file even satisfy this demand?\n",
        "Let's check it by printing one line of data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dzGo42OYBjMj"
      },
      "outputs": [],
      "source": [
        "print(dataset[0])\n",
        "\n",
        "print(type(dataset))\n",
        "print(type(dataset[0]))\n",
        "print(type(dataset[0][0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POPJs3EQBjMj"
      },
      "source": [
        "Our current code for loading a CSV file returns a list of lists with each value being a string (str). As you might guess, now is the time to convert the strings to a floating point number.\n",
        "\n",
        "<div class=\"alert alert-block alert-success\">\n",
        "<b>Task:</b> Create a function called <code>str_column_to_float()</code>. It takes your dataset and the index of a column as input and returns the dataset with the converted column.\n",
        "<ul>\n",
        "<li> Hint: Strip any whitespace from the value before making the conversion.\n",
        "\n",
        "</ul>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BerhMbLBBjMj"
      },
      "outputs": [],
      "source": [
        "# To create a new instance of lists of lists\n",
        "import copy\n",
        "\n",
        "def str_column_to_float(dataset_new: List[List[Any]], column: int) -> List[List[Any]]:\n",
        "    ### STUDENT CODE HERE (1pt)\n",
        "\n",
        "\n",
        "    ### STUDENT CODE until HERE\n",
        "\n",
        "\n",
        "# Now if we add this function to our previous code we can test if it is working correctly:\n",
        "dataset_new: List[List[Any]] = copy.deepcopy(dataset)\n",
        "\n",
        "print(dataset[0])\n",
        "print(dataset_new[0])\n",
        "\n",
        "# convert string columns to float\n",
        "for i in range(len(dataset_new[0])):\n",
        "    dataset_new = str_column_to_float(dataset_new, i)\n",
        "\n",
        "print(dataset_new[0])\n",
        "\n",
        "# A quick test to see if all columns have been converted\n",
        "for row in dataset_new:\n",
        "    for entry in row:\n",
        "        assert type(entry) == float, f'The type expected was float, but found value to be of {type(entry)}.'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RvDyw3TPBjMk"
      },
      "source": [
        "## 1.3 Convert String to Integers\n",
        "\n",
        "Now that you know how to convert strings to floats, we learn how to convert strings to integers. This might seem to be a little bit unnecessary, but to show you that there are cases in which you might prefer to have integers instead of strings we use a different training set.\n",
        "\n",
        "The new dataset is called \"iris.csv\". You can find it in the \"data\" folder. Also you can find more information here: http://archive.ics.uci.edu/ml/datasets/Iris\n",
        "\n",
        "If we now take a small peek into our dataset, we see that there is numeric and character data. In the final column, which is commonly reserved to hold the outcome or the predicted value for a row, is a string.\n",
        "\n",
        "![Iris.png](attachment:Iris.png)\n",
        "\n",
        "We can convert the class value to an integer by creating a \"map\" (aka. dictionary in Python). To do so, we take a closer look at the data and see that there are only the following values: \"Iris-setsosa\", \"Iris-versicolor\" and \"Iris-virginica\". The next step, is to assign each class an integer value, like: 0,1,2. In the end the value of \"Iris-setsosa\" is mapped to e.g. 0 and \"Iris-virginica\" to e.g. 1 and so on ...\n",
        "\n",
        "<div class=\"alert alert-block alert-success\">\n",
        "<b>Task:</b> Create a function, which first of all extract all possible values for a given column and then assigns numbers to this column.\n",
        "<ul>\n",
        "<li> Your function takes the dataset and the column id as input and returns both the lookup table (a dict of the possible values and the corresponding integer values) and the changed dataset.\n",
        "    <li> Hint: Take a look at the build-in <code>set()</code> constructor and the <code>dict()</code> constructor for the structure of the lookup table.\n",
        "    <li> Hint2: You can use then the build-in <code>enumerate()</code> function to fill your lookup table.\n",
        "<li> Then convert the column.\n",
        "</ul>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eFQjhfLOBjMk"
      },
      "outputs": [],
      "source": [
        "# Convert string column to integer\n",
        "def str_column_to_int(dataset: List[List[Any]], column: int) -> Tuple[Dict[int, str], List[List[Any]]]:\n",
        "\n",
        "    ### STUDENT CODE HERE (1pt)\n",
        "\n",
        "\n",
        "    ### STUDENT CODE until HERE\n",
        "\n",
        "    return lookup_reverse, dataset\n",
        "\n",
        "\n",
        "# We'll wrap our testing code inside a method so that we don't clutter the global variables\n",
        "def _test():\n",
        "\n",
        "    # Load a test_dataset to run the previously defined function on\n",
        "    test_dataset = load_csv('data/test.csv')\n",
        "    lookup, dataset = str_column_to_int(test_dataset, 3)\n",
        "\n",
        "    # Check if all variables in the specified columsn are of the type integer\n",
        "    for row in dataset:\n",
        "        if type(row[3]) == int:\n",
        "            int_check = True\n",
        "        else:\n",
        "            int_check = False\n",
        "            print('Conversion of variables to type integer is faulty!')\n",
        "            break\n",
        "    if int_check:\n",
        "        print('Conversion of variables to type Integer is successful!')\n",
        "\n",
        "    # Check if lookup table has been generated as specified\n",
        "    if (type(lookup) == dict) | (len(lookup) == 3):\n",
        "        print('Lookup table is returned successfully!')\n",
        "    else:\n",
        "        print('Lookup table is faulty!')\n",
        "\n",
        "_test()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qww9rjcdBjMk"
      },
      "source": [
        "At the end of this chapter, we want to use everything we learned so far and see if it works all together.\n",
        "\n",
        "<div class=\"alert alert-block alert-success\">\n",
        "<b>Task:</b> Load the Iris Data Set and convert the first four columns to floats and the last one to an integer. In the end print the lookup table, which reveals the data behind your integer column.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MDwYvv9WBjMl"
      },
      "outputs": [],
      "source": [
        "# Load iris dataset\n",
        "filename = 'data/iris.csv'\n",
        "\n",
        "### STUDENT CODE HERE (1pt)\n",
        "\n",
        "dataset: List[List[str]] = ...\n",
        "\n",
        "### STUDENT CODE until HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Evn7BL3GBjMl"
      },
      "source": [
        "## 1.4 Further information on CSV files\n",
        "\n",
        "Before you load your data, you want to get a glimpse behind the curtain, to see the shape of your data. It is important to check your dataset for the following points.\n",
        "\n",
        "Does your dataset have file headers? This might be useful to automatically assign attributes/features to each column of data. If not, you might want to consider naming your attributes manually.\n",
        "\n",
        "In the next step you should check your data for comments. These are indicated in CSV-files with a # at the start of a line. It depends on the method with which you load your dataset, but you might need to indicate, that there might occur some comments in your data.\n",
        "\n",
        "If your data does use a tab or white space instead of a comma you should also specify this explicitly. Moreover, in some CSV files values are quoted with the double quotation mark character (e.g. if your data itself contains commas). If your file differs from that, you also should specify the quote character used in your data.\n",
        "\n",
        "Please have a look at the following code and take a look at the parameters, which are passed to the `csv.reader()` call."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MBeQckYeBjMl"
      },
      "outputs": [],
      "source": [
        "# Load CSV Using Python Standard Library\n",
        "import csv\n",
        "\n",
        "filename = 'data/pima-indians-diabetes.csv'\n",
        "\n",
        "with open(filename, 'rt') as raw_data:\n",
        "    reader = csv.reader(raw_data, delimiter=',', quoting=csv.QUOTE_NONE)\n",
        "\n",
        "    rows: List[List[str]] = list(reader)\n",
        "print(len(rows))\n",
        "print(len(rows[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DwAP0yHBjMm"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "<b>Question (2pts):</b> What can you notice if you load your data like this? Think about the type and size of the loaded dataset with respect to the functions you had to program above.\n",
        "</div>\n",
        "\n",
        "<div class=\"alert alert-block alert-success\">\n",
        "<b>Your Answer:</b>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVE3E1pUBjMm"
      },
      "source": [
        "## 1.5 Load CSV-Files with Pandas\n",
        "\n",
        "In order to load CSV-files in an efficient way in many cases you want to use the `pandas` python package using the function `pandas.read_csv()` (https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html#pandas.read_csv). This function is very flexible and returns a pandas dataframe object, which you can use for summarizing and plotting directly.\n",
        "\n",
        "Please have a look at the following code to see how pandas can be used to read data. Please note, that the `read_csv()` function is able to also take the column \"names\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1BsQ3dj_BjMm"
      },
      "outputs": [],
      "source": [
        "from pandas import read_csv\n",
        "import pandas as pd\n",
        "\n",
        "filename = 'data/pima-indians-diabetes.csv'\n",
        "\n",
        "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
        "data: pd.DataFrame = read_csv(filename, names=names)\n",
        "print(type(data)) # Get the datatype\n",
        "print(data.shape) # Get the columns and rows. Format: (rows, cols)\n",
        "print(data[0:10]) # Get the first 10 values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XfYWuPNuBjMn"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "<b>Question (2pts):</b> What can you notice if you load your data like this? Think about the type and size of the loaded dataset with respect to the functions you had to program above.\n",
        "</div>\n",
        "\n",
        "<div class=\"alert alert-block alert-success\">\n",
        "<b>Your Answer:</b>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFoxaPVXBjMn"
      },
      "source": [
        "# 2 Understand Your Data\n",
        "\n",
        "Now that you know how to load your data we want to give you some tools on how to get a quick overview over your data so you can decide how you can get the most out of it.\n",
        "\n",
        "You can either take a look at the data by opening it, or you can use the pandas package, which offers you a function to give you a peek into the raw data. To do so use the `.head()` function.\n",
        "\n",
        "\n",
        "<div class=\"alert alert-block alert-success\">\n",
        "<b>Task:</b> Write a piece of code, which shows you the first 20 rows of your data. For this you can directly use the data object from above.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qWJ-8zdABjMn"
      },
      "outputs": [],
      "source": [
        "### STUDENT CODE HERE (1pt)\n",
        "\n",
        "\n",
        "### STUDENT CODE until HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMeEmBijBjMo"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "<b>Question (1pts):</b> What do the different abbreviated features (preg, plas etc.) in your dataset stand for?\n",
        "</div>\n",
        "\n",
        "<div class=\"alert alert-block alert-info\">\n",
        "<b>Note:</b> The origin of your dataset - https://www.kaggle.com/uciml/pima-indians-diabetes-database\n",
        "</div>\n",
        "    \n",
        "<div class=\"alert alert-block alert-success\">\n",
        "<b>Your Answer:</b> <br> <ul>\n",
        "    <li> preg: </li>\n",
        "    <li> plas: </li>\n",
        "    <li> pres: </li>\n",
        "    <li> skin: </li>\n",
        "    <li> test: </li>\n",
        "    <li> mass: </li>\n",
        "    <li> pedi: </li>\n",
        "    <li> age: </li>\n",
        "    <li> class: </li>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNcVBjzuBjMo"
      },
      "source": [
        "In the first chapter you learned how to convert different data types. But before you can convert different datatypes you have to know which datatypes you are currently working on. The `.dtypes` attribute from the pandas tells you the datatype of each column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "THVlHE-8BjMo"
      },
      "outputs": [],
      "source": [
        "data.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lpWF3_IBjMp"
      },
      "source": [
        "## 2.1 Descriptive Statistics\n",
        "\n",
        "Now that we have the big picture in terms of its shape, the first lines and the datatypes of our raw data, we might also want to gain information about their attributes. The question here is what is hidden behind the different values. This also gives you the ability to estimate whether your algorithm is working correctly in the end.\n",
        "\n",
        "The `.describe()` method lists 8 statistical properties of each attribute:\n",
        "\n",
        "_count, mean, Standard Deviation, Minimum Value, 25th Percentile, 50th Percentile (Median), 75 Percentile and Maximum Value_\n",
        "\n",
        "<div class=\"alert alert-block alert-success\">\n",
        "<b>Task:</b> Use the describe function on the diabetes dataset.\n",
        "<ul>\n",
        "    <li> Hint: Use the <code>set_option()</code> function from pandas to set the output to a reasonable precision. Set one attribute by ('attribute', value)\n",
        "\n",
        "</ul>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qy3cDtOwBjMp"
      },
      "outputs": [],
      "source": [
        "from pandas import set_option\n",
        "\n",
        "### STUDENT CODE HERE (1pt)\n",
        "\n",
        "description = ...\n",
        "\n",
        "### STUDENT CODE until HERE\n",
        "\n",
        "print(description)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRbBuJczBjMp"
      },
      "source": [
        "## 2.2 Class Distribution\n",
        "\n",
        "Usually your data is not well balanced from the beginning on and there are more samples for one class than for another. This tends to require special handling in the data preparation. To get a quick idea of the status of your data you can sort it by one single attribute."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZZI8KCvBjMp"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "<b>Task:</b> Write a piece of code, which counts and prints the number of occurances for each class.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kVEHTR8hBjMq"
      },
      "outputs": [],
      "source": [
        "### STUDENT CODE HERE (1pt)\n",
        "\n",
        "class_counts = ...\n",
        "\n",
        "### STUDENT CODE until HERE\n",
        "\n",
        "print(class_counts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xKrAEqSBjMq"
      },
      "source": [
        "## 2.3 Correlations between Attributes\n",
        "\n",
        "There are attributes, which usually depend on others. This is also called correlation. A common way to calculate and also measure correlations between attributes is the _Pearson's Correlation Coefficient_. This Coefficient ranges between -1 and 1 for extreme positive or negative correlation, 0 means no correlation. The pandas function `.corr()` calculates a so called _correlation matrix_. It gives the correlation of each variable with respect to all variables. The matrix is symmetric.\n",
        "\n",
        "<div class=\"alert alert-block alert-success\">\n",
        "<b>Task/Question:</b> Use the <code>.corr()</code> method to calculate a correlation matrix and describe what you can tell from it.\n",
        "</div>\n",
        "\n",
        "\n",
        "<div class=\"alert alert-block alert-success\">\n",
        "<b>Your Answer:</b>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qbay7soUBjMq"
      },
      "outputs": [],
      "source": [
        "### STUDENT CODE HERE (1pt)\n",
        "\n",
        "correlations = ...\n",
        "\n",
        "### STUDENT CODE until HERE\n",
        "\n",
        "print(correlations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4M4t-LMiBjMq"
      },
      "source": [
        "# 3 Understand Your Data With Visualization\n",
        "\n",
        "In the last chapter we learned how to get a good insight and overview about our data. But in cases in which our data gets higher dimensional, we can't merely overlook those with numbers, we might need some visualization. In this chapter we will basically treat the same methods, but this time we will visualize them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mQkZX-nBjMr"
      },
      "source": [
        "## 3.1 Histograms\n",
        "\n",
        "To get an idea of the distribution of an attribute you can take a look at a histogram. From the shape of the histogram you can get a quick idea if an attribute is normal distributed or if there is a skew in it.\n",
        "\n",
        "Histograms divide the data into its attributes. One histogram represents the attributes' values by counting their appearance in the dataset.\n",
        "\n",
        "To generate histograms we can use a new library: `matplotlib`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rc3NThXABjMr"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "<b>Task:</b> Generate 9 histograms for each feature in our diabetes dataset.\n",
        "<ul>\n",
        "<li> Hint1: You can either use matplotlib on all features or simply use pandas <code>.hist()</code> method, which uses matplotlib to create one histogram per column.\n",
        "\n",
        "<li> Hint2: Take a look at the matplotlib function <code>tight_layout()</code> and <code>show()</code>.\n",
        "</ul>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5l2y6lkqBjMr"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "### STUDENT CODE HERE (1pt)\n",
        "\n",
        "\n",
        "### STUDENT CODE until HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tc60xOPKBjMs"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "<b>Question (2pts):</b>What can you tell from the histograms. Do they match the findings from the previous chapter?\n",
        "</div>\n",
        "\n",
        "<div class=\"alert alert-block alert-success\">\n",
        "<b>Your Answer:</b>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1xfNI7UBjMs"
      },
      "source": [
        "## 3.2 Density Plots\n",
        "\n",
        "In general a density plot works similar to a histogram. It gives you a smoother shape, since it is not limited by the occurence of values of an attribute."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvvpU81iBjMs"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "<b>Task:</b> Find out how to draw a density plot and generate one for each feature. You might use implemented methods from pandas.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z9ccd66ABjMs"
      },
      "outputs": [],
      "source": [
        "### STUDENT CODE HERE (1pt)\n",
        "\n",
        "\n",
        "### STUDENT CODE until HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-t4cXwzJBjMt"
      },
      "source": [
        "## 3.3 Box and Whisker Plots\n",
        "\n",
        "Another way to visualize your data are so called _boxplots_. These look kind of unfamiliar at the first look. One boxplot shows a line for the median in a box. Moreover the 25th percentile and the 75th percentile are displayed as well. Another line shows the overall range of values (https://en.wikipedia.org/wiki/Box_plot ).\n",
        "\n",
        "The whiskers visualize the spread of the data and the dots symbolize the data values, which are 1.5 greater than the size of the middle 50% of the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00QE2E9rBjMt"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "<b>Task:</b> Use box plots to visualize each feature. You might use implemented methods from pandas.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "SkpbB6GqBjMt"
      },
      "outputs": [],
      "source": [
        "### STUDENT CODE HERE (1pt)\n",
        "\n",
        "\n",
        "### STUDENT CODE until HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwS_WriEBjMu"
      },
      "source": [
        "## 3.4 Multivariate plots\n",
        "\n",
        "### 3.4.1 Correlation Matrix plot\n",
        "\n",
        "As we mentioned in chapter 2, the correlation describes the relationship between two variables. If you have already calculated the correlation matrix, you can move on by visualizing it. This is useful to get a quick overview to analyze the correlation between all attributes. Moreover, it is important to spot highly correlated attributes, since some algorithms can suffer poor performance if there are highly correlated input values.\n",
        "\n",
        "\n",
        "<div class=\"alert alert-block alert-success\">\n",
        "<b>Task:</b> Create a heat map which gives you a good overview of the correlations\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AICbaXjnBjMu"
      },
      "outputs": [],
      "source": [
        "### STUDENT CODE HERE (1pt)\n",
        "\n",
        "\n",
        "### STUDENT CODE until HERE\n",
        "\n",
        "plt.show()\n",
        "data.corr()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwKPCrlUBjMu"
      },
      "source": [
        "There you go, you are having a quick overview of the data.\n",
        "\n",
        "It seems like every attribute is positively correlated with each other, if you want to know which number symbolizes which attribute, you can customize your code and add labels to your axes. It might also be useful to annotate each cell in the heatmap."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0iWCk86dBjMu"
      },
      "source": [
        "### 3.4.2 Scatter Plot Matrix\n",
        "\n",
        "A scatter plot matrix is one of the last methods we present to you. The scatter plot represents the relationship between two variables as dots in two dimensions, one axis for each attribute. It is possible to plot a Scatter Plot for each attribute in your data, named _Scatter Plot Matrix_. One advantage of the Scatter Plot Matrix is that you can see structured relationships between some attributes, which might indicate correlation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFnQcgRFBjMv"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "<b>Task:</b> Plot such a matrix.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pUxs6DXIBjMv"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "<b>Question (2pts):</b> What you can tell from the plot?\n",
        "</div>\n",
        "\n",
        "<div class=\"alert alert-block alert-success\">\n",
        "<b>Your Answer:</b>  \n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6-HwP5voBjMv"
      },
      "outputs": [],
      "source": [
        "from pandas.plotting import scatter_matrix\n",
        "\n",
        "### STUDENT CODE HERE (1pt)\n",
        "\n",
        "\n",
        "### STUDENT CODE until HERE\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h68C2fB6BjMv"
      },
      "source": [
        "## 3.5 Skew of Univariate Distributions\n",
        "\n",
        "Many machine learning algorithms work better when using normal or gaussian distributed (see: https://en.wikipedia.org/wiki/Normal_distribution) input values. However, your data may have a skew. You may want to correct this by proper preparation of your data. Let us have a look at the skew. You can calculate this by using the pandas `.skew()` method.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTwcK9LHBjMw"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "<b>Task/Question (2pts):</b> Calculate the skew of the diabetes data and describe your observations in term of what the numbers show you. See also: https://en.wikipedia.org/wiki/Skewness\n",
        "</div>\n",
        "\n",
        "\n",
        "<div class=\"alert alert-block alert-success\">\n",
        "<b>Your Answer:</b>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UFUnn5OmBjMw"
      },
      "outputs": [],
      "source": [
        "### STUDENT CODE HERE (1pt)\n",
        "\n",
        "skew = ...\n",
        "\n",
        "### STUDENT CODE until HERE\n",
        "\n",
        "print(skew)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ng_yeAtBjMw"
      },
      "source": [
        "# 4 Scale Machine Learning data\n",
        "\n",
        "Since we are now able to load and analyze our raw data, we are capable of the first big step in preparing our data. This step is to scale your data, because many machine learning algorithms expect scaled data as input. In this chapter we will learn how to normalize and standardize data and when you have to choose normalizing over standardizing. This is especially important for artificial neural networks and deep learning.\n",
        "\n",
        "## 4.1 Min-Max-Scale / Normalize data\n",
        "\n",
        "Normalizing should already sound familiar to you from your mathematics class. We shape the values into a range between 0 and 1. To realize this we have to know the maximum and the minimum value for each attribute. A simple option to do this, is to enumerate through the values.\n",
        "\n",
        "<div class=\"alert alert-block alert-success\">\n",
        "<b>Task:</b> Write a function <code>dataset_minmax()</code>, which calculates the minimum and maximum for each attribute.\n",
        "<ul>\n",
        "    <li> Hint: Your function takes the dataset as input and returns a list with a tuple (min, max) for each column in the dataset\n",
        "\n",
        "</ul>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l3QsB49yBjMw"
      },
      "outputs": [],
      "source": [
        "# Find the min and max values for each column\n",
        "def dataset_minmax(dataset: List[List[float]]) -> List[Tuple[float, float]]:\n",
        "\n",
        "    ### STUDENT CODE HERE (1pt)\n",
        "\n",
        "\n",
        "    ### STUDENT CODE until HERE\n",
        "    return minmax\n",
        "\n",
        "# small test dataset\n",
        "dataset = [[50, 30], [20, 90]]\n",
        "print(dataset)\n",
        "\n",
        "# Calculate min and max for each column\n",
        "minmax: List[Tuple[float, float]] = dataset_minmax(dataset)\n",
        "print(minmax)\n",
        "\n",
        "\n",
        "# compare your result with the checkpoint\n",
        "lama_compare_checkpoint(minmax, 't1/checkpoint1.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TAsDxqXuBjMx"
      },
      "source": [
        "Now we can get the minimum and maximum for each column. Using these values we can add a function, which normalizes our values based on the following formula:\n",
        "\n",
        "$$scaled\\, value = \\frac{value - min}{max-min}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IcM1sAVMBjMx"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "<b>Task:</b> Implement this formula in a function, which is named <code>normalize_dataset()</code>.\n",
        "<ul>\n",
        "    <li> Hint: It uses the dataset and the minmax values and returns the normalized dataset.\n",
        "\n",
        "</ul>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZNR6AcmTBjMx"
      },
      "outputs": [],
      "source": [
        "def normalize_dataset(dataset: List[List[float]], minmax: List[Tuple[float, float]]) -> List[List[float]]:\n",
        "\n",
        "    return_dataset: List[List[float]] = []\n",
        "\n",
        "    ### STUDENT CODE HERE (1pt)\n",
        "\n",
        "\n",
        "    ### STUDENT CODE until HERE\n",
        "\n",
        "    return return_dataset\n",
        "\n",
        "## Now we got the necessary tools for normalizing our data, by combining our functions.\n",
        "\n",
        "# Again a small test dataset\n",
        "dataset = [[50, 30], [20, 90], [30, 40]]\n",
        "print(dataset)\n",
        "\n",
        "# Calculate min and max for each column\n",
        "minmax: List[Tuple[float, float]] = dataset_minmax(dataset)\n",
        "print(minmax)\n",
        "\n",
        "# Normalize columns\n",
        "dataset: List[List[float]] = normalize_dataset(dataset, minmax)\n",
        "print(dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVJPBUkZBjMy"
      },
      "source": [
        "Now we have to put it all together.\n",
        "\n",
        "<div class=\"alert alert-block alert-success\">\n",
        "<b>Task:</b> Write a function called <code>load_normalized_csv()</code>, which loads a CSV file and normalizes the data afterwards.\n",
        "<ul>\n",
        "        <li> Hint: Your function takes the filename as input parameter and returns the normalized dataset. Use your <code>load_csv()</code> function.\n",
        "\n",
        "</ul>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6CZ0R3erBjMy"
      },
      "outputs": [],
      "source": [
        "def load_normalized_csv(filename: str) -> List[List[float]]:\n",
        "\n",
        "    ### STUDENT CODE HERE (1pt)\n",
        "\n",
        "\n",
        "    ### STUDENT CODE until HERE\n",
        "\n",
        "## Test:\n",
        "filename = 'data/pima-indians-diabetes.csv'\n",
        "\n",
        "dataset: List[List[float]] = load_normalized_csv(filename)\n",
        "\n",
        "print(dataset[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlB1Oef4BjMy"
      },
      "source": [
        "## 4.2 Standardize data\n",
        "\n",
        "If you standardize data you want to center your distribution on the value 0 and the standard deviation on 1. The outcome will be a Gaussian or normal distribution also called bell curve.\n",
        "\n",
        "First of all to standardize data we have to know the mean and standard deviation of the values for each column. Therefore we will start by writing a function, which calculates the mean value for each column based on the following formula:\n",
        "\n",
        "$$\\bar{x} = \\frac{\\sum_{n=1}^{N} x_n}{N}$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eW1p3xLNBjMy"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "<b>Task:</b> Write a function <code>column_means()</code> which returns the mean value for each column.\n",
        "<ul>\n",
        "        <li> Hint: Your return's type is a list (with the mean for each column).\n",
        "\n",
        "</ul>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JNmJg403BjMz"
      },
      "outputs": [],
      "source": [
        "def column_means(dataset: List[List[float]]) -> List[float]:\n",
        "\n",
        "    ### STUDENT CODE HERE (1pt)\n",
        "\n",
        "\n",
        "    ### STUDENT CODE until HERE\n",
        "\n",
        "    return means\n",
        "\n",
        "\n",
        "# As usual we are going to run a quick test on our function using a small test dataset\n",
        "test_dataset = [[50, 30], [20, 90], [30, 40]]\n",
        "print(test_dataset)\n",
        "\n",
        "# Calculate the mean for each column\n",
        "test_means: List[float] = column_means(test_dataset)\n",
        "print(test_means)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcf2hY_TBjMz"
      },
      "source": [
        "As you may know from your probability classes, the empricial standard deviation describes the average spread of the values from the mean. The following formula will help you write a function which calculates the standard deviation.\n",
        "\n",
        "\n",
        "$$ s = \\sqrt{\\frac{\\sum\\nolimits_{n=1}^N(x_n - \\bar{x})^2}{N -1}}$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQPwSXoKBjMz"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "<b>Task:</b> Write a function <code>column_stdevs()</code> which calculates the standard deviation for each column based on the given formula.\n",
        "<ul>\n",
        "        <li> Hint: Your return's type is a list (with the mean for each column).\n",
        "\n",
        "</ul>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JujDiPJTBjMz"
      },
      "outputs": [],
      "source": [
        "from math import sqrt\n",
        "\n",
        "def column_stdevs(dataset: List[List[float]], means: List[float]) -> List[float]:\n",
        "\n",
        "    ### STUDENT CODE HERE (1pt)\n",
        "\n",
        "\n",
        "    ### STUDENT CODE until HERE\n",
        "\n",
        "    return stdevs\n",
        "\n",
        "\n",
        "# As usual we are going to run a quick test on our function using a small test dataset\n",
        "test_dataset = [[50, 30], [20, 90], [30, 40]]\n",
        "print(test_dataset)\n",
        "\n",
        "# Calculate the standard deviation for each column also using the mean calulation\n",
        "test_means: List[float] = column_means(test_dataset)\n",
        "test_stdevs: List[float] = column_stdevs(test_dataset, test_means)\n",
        "print(test_stdevs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Li6CfpdrBjM0"
      },
      "source": [
        "Now we have gathered all required tools and can start with standardizing data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZsgGVKBBjM0"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "<b>Task:</b>\n",
        "<ul>\n",
        "<li> Use a statistic method to standardize the values and write a function <code>standardize_dataset()</code> which does so.\n",
        "<li> Run all required functions and display your data in a histogram.\n",
        "</ul>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wf1AtAJEBjM1"
      },
      "outputs": [],
      "source": [
        "def standardize_dataset(dataset: List[List[float]], means: List[float], stdevs: List[float]) -> List[List[float]]:\n",
        "    return_dataset: List[List[float]] = []\n",
        "\n",
        "    ### STUDENT CODE HERE (1pt)\n",
        "\n",
        "\n",
        "    ### STUDENT CODE until HERE\n",
        "\n",
        "    return return_dataset\n",
        "\n",
        "\n",
        "##  Now it is time to put it all together an give your standardization a try.\n",
        "\n",
        "# A small test dataset to try your code on\n",
        "dataset = [[50, 10, 30], [20, 25, 90], [30, 40, 50]]\n",
        "print(dataset)\n",
        "\n",
        "### STUDENT CODE HERE (1pt)\n",
        "\n",
        "\n",
        "### STUDENT CODE until HERE\n",
        "\n",
        "\n",
        "\n",
        "# compare your result with the checkpoint\n",
        "lama_compare_checkpoint(std_dataset, 't1/checkpoint2.pkl')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMkOeVJWBjM1"
      },
      "source": [
        "Ok. Now let us also create a function which reads a given CSV file and standardizes it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twxC6IdNBjM1"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "<b>Task:</b> Complete the <code>load_standardized_csv()</code> function.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Thiy8cRmBjM1"
      },
      "outputs": [],
      "source": [
        "def load_standardized_csv(filename: str) -> List[List[float]]:\n",
        "\n",
        "    ### STUDENT CODE HERE (1pt)\n",
        "\n",
        "    dataset = ...   # Load file\n",
        "\n",
        "    ### STUDENT CODE until HERE\n",
        "\n",
        "## Test:\n",
        "filename = 'data/pima-indians-diabetes.csv'\n",
        "\n",
        "dataset: List[List[float]] = load_standardized_csv(filename)\n",
        "\n",
        "print(dataset[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fs_6G_rRBjM2"
      },
      "source": [
        "## 4.3 When to normalize and when to standardize?\n",
        "\n",
        "Now that you know how to realize both methods, it is important to know which one has to be used. Standardization works if your data conforms to a normal distribution. If your data confirms with this, standardizing is the method of choice. If your data doesn't have a specific distribution you should consider to normalize it before you apply your machine learning algorithm.\n",
        "\n",
        "You can also use many other data transformation methods. The idea behind this transformation is to expose the structure of your data to the learning algorithm in the best possible way. In some cases it might not be clear which transformation is the best to use. In this cases trial and error help to get kind of a feeling for transformations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bo3hvB5LBjM2"
      },
      "source": [
        "# 5 Prepare your data for machine learning\n",
        "\n",
        "This is the last chapter of the data preparation tutorial. As we learned in the previous chapter, it is a good idea to prepare your data in a way that exposes the unique structure of your data. Also we created a simple python code, to go one step further. We will now use the package _scikit-learn_. After completing this lesson we will be able to rescale, normalize, standardize and binarize your data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MonwbyABjM2"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "<b>Question (2pts):</b> The scikit-learn library contains different standard approaches for transforming data, the funtions 'fit', 'transform' and 'fit_transform'. Research and describe the difference.\n",
        "</div>\n",
        "\n",
        "<div class=\"alert alert-block alert-success\">\n",
        "<b>Your Answer:</b>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MuZlgrgBjM2"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "<b>Hint (2pts):</b> The labels are already binary so remember, during the following sclaing excercises, not to scale the labels along with the rest of the data\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYIc3EbGBjM2"
      },
      "source": [
        "## 5.1 Min-Max-Scale / Normalize data\n",
        "\n",
        "When we normalize our dataset the maximum value becomes 1. This is useful for datasets with lots of zeros and varying scales. For example if we use algorithms where input values are weighted such as neural networks.\n",
        "\n",
        "With scikit-learn you can use the `MinMaxScaler` class to rescale your attributes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erenIYq2BjM2"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "<b>Task:</b> Rescale/Normalize the data from the diabetes example with scikit-learn, by using the <code>MinMaxScaler</code> and print the first 5 rows of the rescaled dataset.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MbCaMpUkBjM2"
      },
      "outputs": [],
      "source": [
        "# Rescale data (between 0 and 1)\n",
        "from pandas import read_csv\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "filename = 'data/pima-indians-diabetes.csv'\n",
        "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
        "\n",
        "### STUDENT CODE HERE (1pt)\n",
        "\n",
        "rescaledX: np.ndarray = ...\n",
        "\n",
        "### STUDENT CODE until HERE\n",
        "\n",
        "set_printoptions(precision=3)\n",
        "print(rescaledX[0:5,:])\n",
        "\n",
        "\n",
        "# compare your result with the checkpoint\n",
        "lama_compare_checkpoint(rescaledX, 't1/checkpoint3.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVJqR80-BjM3"
      },
      "source": [
        "## 5.2 Standardize data\n",
        "\n",
        "As we mentioned in the previous chapter, machine learning requires a gaussian distribution as input variables and works better with rescaled data. The output of a standardization is a distribution with a mean of zero and a standard deviation of 1.\n",
        "\n",
        "You can standardize data by using the `StandardScaler` class in scikit-learn."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FV1mCF8eBjM3"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "<b>Task:</b> Standardize the diabetes example by using the <code>StandardScaler</code> and print the first 5 rows of the dataset\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MuMkkwnyBjM3"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "### STUDENT CODE HERE (1pt)\n",
        "\n",
        "rescaledX: np.ndarray = ...\n",
        "\n",
        "### STUDENT CODE until HERE\n",
        "\n",
        "\n",
        "# compare your result with the checkpoint\n",
        "lama_compare_checkpoint(rescaledX, 't1/checkpoint4.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcLBs8gIBjM3"
      },
      "source": [
        "## 5.3 Normalize data\n",
        "\n",
        "With scikit-learn's `Normalizer`class you can normalize samples to have **unit norm** (by a given norm, for example L1 or L2). See also: https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing-normalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dr9f7cdfBjM4"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "<b>Task:</b> Normalize the diabetes example with L1-norm, by using the <code>normalize</code> function and print the first 5 rows of your dataset\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "joH6SAnJBjM4"
      },
      "outputs": [],
      "source": [
        "# Normalize data (length of 1)\n",
        "from sklearn.preprocessing import normalize\n",
        "\n",
        "### STUDENT CODE HERE (1pt)\n",
        "\n",
        "normalizedX: np.ndarray = ...\n",
        "\n",
        "### STUDENT CODE until HERE\n",
        "\n",
        "print(normalizedX[0:5,:])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K96UimWsBjM4"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "<b>Question (1pt):</b> What property does one sample now fulfill?\n",
        "</div>\n",
        "\n",
        "<div class=\"alert alert-block alert-success\">\n",
        "<b>Your Answer:</b>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNI7yTzrBjM4"
      },
      "source": [
        "## 5.4 Binarize data\n",
        "\n",
        "A new method to pre-process data is binarization. As you might guess you can set a threshold and every value above it will be assigned the value one and values equal or below the threshold will be assigned the value 0.\n",
        "With scikit-learn you can use the class `Binarizer`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxCdGbJpBjM5"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "<b>Task:</b> Binarize the diabetes example and print the first 5 rows.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hyCJDxYZBjM5"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import Binarizer\n",
        "\n",
        "### STUDENT CODE HERE (1pt)\n",
        "\n",
        "binaryX: np.ndarray = ...\n",
        "\n",
        "### STUDENT CODE until HERE\n",
        "\n",
        "print(binaryX[0:5,:])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fY4-0VdiBjM6"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "<b>Question:</b> Is binarizing this particular dataset useful? Explain briefly why we should or shouldn't binarize this dataset!\n",
        "</div>\n",
        "<div class=\"alert alert-block alert-success\">\n",
        "<b>Your Answer:</b>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iH4Ji93pBjM7"
      },
      "source": [
        "# 6 Wrap up\n",
        "\n",
        "In this session you have seen how you can properly read, understand and prepare data. This is a very important step before algorithms come into play. Remember that your algorithm can only perform well, if you have proper data!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suaSqFyZBjM9"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "<b>Task:</b>\n",
        "    <ul>\n",
        "        <li>Summarize in three to five sentences what methods you have learned today\n",
        "        <li>Make two statements about the dataset, for example the more children a person has, the older the person is on average.\n",
        "        <li>You may use some plots or prints if you want to.\n",
        "    </ul>\n",
        "</div>\n",
        "<div class=\"alert alert-block alert-success\">\n",
        "<b>Your Answer:</b>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GYH1buH8BjM9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UV1aAyOJBjM9"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "83ba11a6a2c2c1d1a57e5e709143b398122ace0b3b5cfdc560826bd5bb2b1da5"
    },
    "kernelspec": {
      "display_name": "LAMA Kernel 2023",
      "language": "python",
      "name": "lama-kernel"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "metadata": {
      "interpreter": {
        "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
      }
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {
        "height": "792px",
        "left": "280px",
        "top": "111.133px",
        "width": "262.4px"
      },
      "toc_section_display": true,
      "toc_window_display": true
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}